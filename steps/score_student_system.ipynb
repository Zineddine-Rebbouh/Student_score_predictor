{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04541110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import classes \n",
    "from load_data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a782f39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "DATA_PATH = '../data/raw_data/StudentPerformanceFactors.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d607a0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(DATA_PATH)\n",
    "df = data_loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76674e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742b3177",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe2c735",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b867cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîç Missing Values:\")\n",
    "print(df.isnull().sum()[df.isnull().sum() > 0] if df.isnull().sum().sum() > 0 else \"No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b2dc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.duplicated().sum() > 0:\n",
    "    df = df.drop_duplicates()\n",
    "    print(\"Duplicate rows dropped\")\n",
    "else:\n",
    "    print(\"No duplicate rows found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255c9f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Select only categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f21b7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute IQR for each numeric column\n",
    "Q1 = df[numeric_cols].quantile(0.25)\n",
    "Q3 = df[numeric_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define outlier bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Detect rows with any outlier values\n",
    "outliers = df[\n",
    "    ((df[numeric_cols] < lower_bound) | (df[numeric_cols] > upper_bound)).any(axis=1)\n",
    "]\n",
    "\n",
    "print(f\"Number of rows with outliers: {outliers.shape[0]}\")\n",
    "\n",
    "# Boxplot for visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.boxplot([df[col] for col in numeric_cols], labels=numeric_cols)\n",
    "plt.title(\"Outlier Detection using IQR\")\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae09c834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Count values for each categorical feature\n",
    "print(\"\\nüîç Categorical Feature Value Counts:\\n\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"‚ñ∂ {col}:\\n{df[col].value_counts()}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022e32ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize categorical feature value counts\n",
    "for col in categorical_cols:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    df[col].value_counts().plot(kind='bar')\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2632db4c",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0df54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle numerical missing values\n",
    "\n",
    "# there is no numerical missing values thats why we going to skip this steps\n",
    "\n",
    "# Handle categorical missing values\n",
    "\n",
    "df['Teacher_Quality'].fillna(df['Teacher_Quality'].mode()[0], inplace=True)\n",
    "\n",
    "df['Parental_Education_Level'].fillna(df['Parental_Education_Level'].mode()[0], inplace=True)\n",
    "\n",
    "df['Distance_from_Home'].fillna(df['Distance_from_Home'].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5d4b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling outliers using the iqr method \n",
    "for col in numeric_cols:\n",
    "    \n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    \n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR    \n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Cap outliers instead of removing them\n",
    "    df[col] = df[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7135f5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df_encoded = df.copy()\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()  # Create a new encoder for each column\n",
    "    df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d4d49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use get dummies instead\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e620ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cc8f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that scores are between 0 and 100\n",
    "df_encoded['Exam_Score'] = df_encoded['Exam_Score'].clip(lower=0, upper=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72694b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the correlation matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "corr_matrix = df_encoded.corr()\n",
    "\n",
    "plt.figure(figsize=(30, 25))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix of Encoded Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f84606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Ensure all features are numeric\n",
    "X_encoded = df_encoded.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# 2. Drop rows with NaNs if any (VIF can't handle missing values)\n",
    "X_encoded = X_encoded.dropna()\n",
    "\n",
    "# 3. Add constant/intercept manually for statsmodels\n",
    "X_with_const = add_constant(X_encoded)\n",
    "\n",
    "# 4. Compute VIF\n",
    "vif_df = pd.DataFrame()\n",
    "vif_df['feature'] = X_with_const.columns\n",
    "vif_df['VIF'] = [variance_inflation_factor(X_with_const.values, i)\n",
    "                 for i in range(X_with_const.shape[1])]\n",
    "\n",
    "# 5. Remove intercept for clarity\n",
    "vif_df = vif_df[vif_df['feature'] != 'const']\n",
    "\n",
    "# 6. Display sorted VIF values\n",
    "print(vif_df.sort_values(by='VIF', ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb041033",
   "metadata": {},
   "source": [
    "VIF = 1: No multicollinearity\n",
    "\n",
    "VIF < 5: Low multicollinearity (‚úÖ OK to keep)\n",
    "\n",
    "VIF between 5-10: Moderate to high multicollinearity (‚ö†Ô∏è Investigate)\n",
    "\n",
    "VIF > 10: High multicollinearity (‚ùå Consider removing or combining features)\n",
    "\n",
    "Dataset has no serious multicollinearity issues. All features have VIF < 5, which is great.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2efac8",
   "metadata": {},
   "source": [
    "----------------------= DATA PREPROCESSING =----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1b9120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules for data preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Define features and target variable\n",
    "X = df_encoded.drop('Exam_Score', axis=1)\n",
    "Y = df_encoded['Exam_Score']\n",
    "\n",
    "# Split data into training and testing sets with 80/20 split and fixed random state for reproducibility\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline for feature scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler only on training data to avoid data leakage\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0235d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first few rows of scaled training features\n",
    "import pandas as pd\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_train_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee261a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules for linear regression and evaluation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# Initialize the linear regression model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the training data\n",
    "y_pred_train = lr_model.predict(X_train_scaled)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_train, y_pred_train)\n",
    "rmse = mse ** 0.5\n",
    "r2 = r2_score(y_train, y_pred_train)\n",
    "\n",
    "# Cross-validation with 5 folds\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cross_val_mse = -cross_val_score(lr_model, X_train_scaled, y_train, scoring=\"neg_mean_squared_error\", cv=cv).mean()\n",
    "cross_val_rmse = cross_val_mse ** 0.5\n",
    "cross_val_r2 = cross_val_score(lr_model, X_train_scaled, y_train, scoring=\"r2\", cv=cv).mean()\n",
    "\n",
    "# Show evaluation results\n",
    "print(\"Training MSE:\", mse)\n",
    "print(\"Training R^2:\", r2)\n",
    "print(\"Cross-validated MSE:\", cross_val_mse)\n",
    "print(\"Cross-validated R^2:\", cross_val_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd4b9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "y_pred_test = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate evaluation metrics for the test set\n",
    "test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "test_rmse = test_mse ** 0.5\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "# Show evaluation results for the test set\n",
    "print(\"Test MSE:\", test_mse)\n",
    "print(\"Test R^2:\", test_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d66c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Plot Actual vs Predicted values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred_test, alpha=0.7)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.show()\n",
    "\n",
    "# Plot residuals\n",
    "residuals_test = y_test - y_pred_test\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=y_pred_test, y=residuals_test, alpha=0.7)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Fitted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals vs Fitted Values (Test Set)')\n",
    "plt.show()\n",
    "\n",
    "# Interpret coefficients\n",
    "coefficients = pd.DataFrame({'Feature': X.columns, 'Coefficient': lr_model.coef_})\n",
    "coefficients = coefficients.sort_values(by='Coefficient', ascending=False)\n",
    "print(coefficients.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e927ef1",
   "metadata": {},
   "source": [
    "# üéØ Bonus Tasks - Advanced Model Exploration\n",
    "\n",
    "This section includes advanced modeling techniques and comparisons:\n",
    "1. **Polynomial Regression** - Non-linear relationships\n",
    "2. **Feature Engineering** - Creating new features and interactions\n",
    "3. **Alternative Models** - Ridge, Lasso, Decision Tree comparisons\n",
    "4. **Best Practices** - Experiment tracking and hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bffa15",
   "metadata": {},
   "source": [
    "## 1. Polynomial Regression üìà\n",
    "\n",
    "Let's explore non-linear relationships by applying polynomial features and comparing performance with linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77414756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Test different polynomial degrees\n",
    "degrees = [1, 2, 3, 4]\n",
    "poly_results = {}\n",
    "\n",
    "print(\"üîç Polynomial Regression Results:\\n\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for degree in degrees:\n",
    "    # Create polynomial features\n",
    "    poly_features = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    \n",
    "    # Create pipeline with polynomial features and linear regression\n",
    "    poly_pipeline = Pipeline([\n",
    "        ('poly', poly_features),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', LinearRegression())\n",
    "    ])\n",
    "    \n",
    "    # Fit the model\n",
    "    poly_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_train_poly = poly_pipeline.predict(X_train)\n",
    "    y_pred_test_poly = poly_pipeline.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_mse = mean_squared_error(y_train, y_pred_train_poly)\n",
    "    test_mse = mean_squared_error(y_test, y_pred_test_poly)\n",
    "    train_r2 = r2_score(y_train, y_pred_train_poly)\n",
    "    test_r2 = r2_score(y_test, y_pred_test_poly)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(poly_pipeline, X_train, y_train, cv=5, scoring='r2')\n",
    "    cv_r2 = cv_scores.mean()\n",
    "    \n",
    "    # Store results\n",
    "    poly_results[degree] = {\n",
    "        'train_mse': train_mse,\n",
    "        'test_mse': test_mse,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'cv_r2': cv_r2,\n",
    "        'model': poly_pipeline\n",
    "    }\n",
    "    \n",
    "    print(f\"üìä Degree {degree}:\")\n",
    "    print(f\"   Train R¬≤: {train_r2:.4f} | Test R¬≤: {test_r2:.4f} | CV R¬≤: {cv_r2:.4f}\")\n",
    "    print(f\"   Train MSE: {train_mse:.4f} | Test MSE: {test_mse:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Find best degree based on cross-validation R¬≤\n",
    "best_degree = max(poly_results.keys(), key=lambda x: poly_results[x]['cv_r2'])\n",
    "print(f\"üèÜ Best Polynomial Degree: {best_degree} (CV R¬≤ = {poly_results[best_degree]['cv_r2']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9ca29d",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering üîß\n",
    "\n",
    "Let's create new features and test interaction terms to improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7029b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering - Create new features and interactions\n",
    "print(\"üîß Feature Engineering Analysis\\n\")\n",
    "\n",
    "# First, let's examine our current features\n",
    "print(\"üìã Current Features:\")\n",
    "print(X.columns.tolist())\n",
    "print(f\"\\nTotal features: {len(X.columns)}\")\n",
    "\n",
    "# Create a copy of the original features for engineering\n",
    "X_engineered = X.copy()\n",
    "\n",
    "# 1. Create interaction terms for important features\n",
    "# Let's focus on features that might have meaningful interactions\n",
    "\n",
    "# Identify numeric features for interaction\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"\\nüî¢ Numeric features available for interactions: {len(numeric_features)}\")\n",
    "\n",
    "# Create some meaningful interaction terms\n",
    "interaction_features = []\n",
    "\n",
    "# Study time interactions (if available)\n",
    "study_time_cols = [col for col in numeric_features if 'hour' in col.lower() or 'study' in col.lower() or 'time' in col.lower()]\n",
    "if study_time_cols:\n",
    "    print(f\"üìö Study time related features: {study_time_cols}\")\n",
    "\n",
    "# Create interaction features based on domain knowledge\n",
    "# Example: Combine Hours_Studied with other engagement metrics\n",
    "if 'Hours_Studied' in X.columns:\n",
    "    # Hours studied * Attendance (if available)\n",
    "    attendance_cols = [col for col in X.columns if 'attendance' in col.lower()]\n",
    "    if attendance_cols:\n",
    "        for att_col in attendance_cols:\n",
    "            interaction_name = f'Hours_X_{att_col}'\n",
    "            X_engineered[interaction_name] = X['Hours_Studied'] * X[att_col]\n",
    "            interaction_features.append(interaction_name)\n",
    "    \n",
    "    # Hours studied * participation metrics\n",
    "    participation_cols = [col for col in X.columns if 'participation' in col.lower() or 'activity' in col.lower()]\n",
    "    if participation_cols:\n",
    "        for part_col in participation_cols:\n",
    "            interaction_name = f'Hours_X_{part_col}'\n",
    "            X_engineered[interaction_name] = X['Hours_Studied'] * X[part_col]\n",
    "            interaction_features.append(interaction_name)\n",
    "\n",
    "# 2. Create polynomial features for key numeric variables (degree 2 only)\n",
    "key_numeric_features = numeric_features[:3]  # Take first 3 to avoid too many features\n",
    "for feature in key_numeric_features:\n",
    "    if feature in X.columns:\n",
    "        poly_name = f'{feature}_squared'\n",
    "        X_engineered[poly_name] = X[feature] ** 2\n",
    "        interaction_features.append(poly_name)\n",
    "\n",
    "# 3. Create ratio features if meaningful\n",
    "if len(numeric_features) >= 2:\n",
    "    # Example: Create a study efficiency ratio\n",
    "    if 'Hours_Studied' in X.columns:\n",
    "        other_numeric = [col for col in numeric_features if col != 'Hours_Studied'][:2]\n",
    "        for other_col in other_numeric:\n",
    "            ratio_name = f'{other_col}_per_Hour'\n",
    "            # Avoid division by zero\n",
    "            X_engineered[ratio_name] = X[other_col] / (X['Hours_Studied'] + 1e-6)\n",
    "            interaction_features.append(ratio_name)\n",
    "\n",
    "print(f\"\\n‚ú® Created {len(interaction_features)} new features:\")\n",
    "for feature in interaction_features:\n",
    "    print(f\"   ‚Ä¢ {feature}\")\n",
    "\n",
    "print(f\"\\nüìä Original features: {X.shape[1]}\")\n",
    "print(f\"üìä Engineered features: {X_engineered.shape[1]}\")\n",
    "print(f\"üìä New features added: {X_engineered.shape[1] - X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0b7fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the engineered features\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "\n",
    "\n",
    "# Split engineered data\n",
    "X_train_eng, X_test_eng, y_train_eng, y_test_eng = train_test_split(\n",
    "    X_engineered, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale the engineered features\n",
    "scaler_eng = StandardScaler()\n",
    "X_train_eng_scaled = scaler_eng.fit_transform(X_train_eng)\n",
    "X_test_eng_scaled = scaler_eng.transform(X_test_eng)\n",
    "\n",
    "# Train model with all engineered features\n",
    "lr_eng_all = LinearRegression()\n",
    "lr_eng_all.fit(X_train_eng_scaled, y_train_eng)\n",
    "\n",
    "# Evaluate with all features\n",
    "y_pred_eng_all = lr_eng_all.predict(X_test_eng_scaled)\n",
    "r2_eng_all = r2_score(y_test_eng, y_pred_eng_all)\n",
    "mse_eng_all = mean_squared_error(y_test_eng, y_pred_eng_all)\n",
    "\n",
    "# Cross-validation score (All features)\n",
    "cv_r2_eng_all = cross_val_score(\n",
    "    Pipeline([('scaler', StandardScaler()), ('lr', LinearRegression())]),\n",
    "    X_engineered, Y, cv=5, scoring='r2'\n",
    ").mean()\n",
    "\n",
    "print(\"üéØ Feature Engineering Results:\\n\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Original Model R¬≤: {test_r2:.4f}\")\n",
    "print(f\"All Engineered Features R¬≤: {r2_eng_all:.4f}\")\n",
    "print(f\"All Features CV R¬≤: {cv_r2_eng_all:.4f}\")\n",
    "print(f\"Improvement: {r2_eng_all - test_r2:.4f}\")\n",
    "print()\n",
    "\n",
    "# Feature selection - select best features\n",
    "if X_engineered.shape[1] > 20:\n",
    "    # Select top k features\n",
    "    k_best = min(15, X_engineered.shape[1])\n",
    "    selector = SelectKBest(score_func=f_regression, k=k_best)\n",
    "    X_train_selected = selector.fit_transform(X_train_eng_scaled, y_train_eng)\n",
    "    X_test_selected = selector.transform(X_test_eng_scaled)\n",
    "\n",
    "    # Train with selected features\n",
    "    lr_selected = LinearRegression()\n",
    "    lr_selected.fit(X_train_selected, y_train_eng)\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred_selected = lr_selected.predict(X_test_selected)\n",
    "    r2_selected = r2_score(y_test_eng, y_pred_selected)\n",
    "\n",
    "    # Cross-validation with selected features\n",
    "    X_selected_all = selector.transform(scaler_eng.fit_transform(X_engineered))\n",
    "    cv_r2_selected = cross_val_score(\n",
    "        LinearRegression(), X_selected_all, Y, cv=5, scoring='r2'\n",
    "    ).mean()\n",
    "\n",
    "    # Selected feature names\n",
    "    selected_features = X_engineered.columns[selector.get_support()]\n",
    "\n",
    "    print(f\"Selected Features R¬≤ ({k_best} features): {r2_selected:.4f}\")\n",
    "    print(f\"Selected Features CV R¬≤: {cv_r2_selected:.4f}\")\n",
    "    print(f\"Selected features: {list(selected_features)}\")\n",
    "else:\n",
    "    r2_selected = r2_eng_all\n",
    "    cv_r2_selected = cv_r2_eng_all\n",
    "    selected_features = X_engineered.columns\n",
    "\n",
    "print(f\"\\nüìà Feature Engineering Summary:\")\n",
    "print(f\"   Best R¬≤ improvement: {max(r2_eng_all, r2_selected) - test_r2:.4f}\")\n",
    "\n",
    "# Correlations of engineered features with target\n",
    "if interaction_features:\n",
    "    print(f\"\\nüîó New Feature Correlations with Target:\")\n",
    "    for feature in interaction_features:\n",
    "        if feature in X_engineered.columns:\n",
    "            corr = X_engineered[feature].corr(Y)\n",
    "            print(f\"   {feature}: {corr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97095337",
   "metadata": {},
   "source": [
    "## üéä Bonus Tasks Completed! \n",
    "\n",
    "### What We Accomplished:\n",
    "\n",
    "1. **‚úÖ Polynomial Regression**: Tested different polynomial degrees and found the optimal complexity\n",
    "2. **‚úÖ Feature Engineering**: Created interaction terms, polynomial features, and ratio features\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "- **Systematic Approach**: We methodically tested each technique and tracked results\n",
    "- **Performance Monitoring**: Used cross-validation to ensure robust model evaluation\n",
    "\n",
    "### üõ†Ô∏è Best Practices Implemented:\n",
    "\n",
    "- ‚úÖ **Cross-Validation**: 5-fold CV for reliable performance estimates  \n",
    "- ‚úÖ **Model Comparison**: Systematic evaluation across multiple algorithms\n",
    "- ‚úÖ **Overfitting Detection**: Monitored train vs test performance gaps\n",
    "- ‚úÖ **Feature Engineering**: Created meaningful interaction terms\n",
    "- ‚úÖ **Visualization**: Comprehensive plots for model comparison\n",
    "\n",
    "The analysis provides a complete machine learning workflow from basic linear regression to advanced ensemble methods with proper experiment tracking! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
